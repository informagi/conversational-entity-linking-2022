{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the existence of the models\n",
    "assert os.path.exists('./bert_conv-td'), 'MD model file not found. Please download the model file following the instructions in the README.md.'\n",
    "assert os.path.exists('./rel_conv_project_folder'), 'ED model file not found. Please download the model file following the instructions in the README.md.'\n",
    "assert os.path.exists('./s2e_pe/model/s2e_ast_onto'), 'PE Linking model folder not found. Please download the model file following the instructions in the README.md.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    for res in results:\n",
    "        print(f'{res[\"speaker\"][:4]}: {res[\"utterance\"]}')\n",
    "        if res[\"speaker\"] == 'SYSTEM': continue\n",
    "        for ann in res['annotations']:\n",
    "            print('\\t', ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hjoko/conda_env_hjoko/220429_conel22_github/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No LR model found, confidence scores ED will be set to zero.\n",
      "Loading model from given path: ./rel_conv_project_folder/wiki_2019/generated/model\n"
     ]
    }
   ],
   "source": [
    "from conv_el import ConvEL\n",
    "cel = ConvEL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/scratch/hjoko/conda_env_hjoko/220429_conel22_github/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2263: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "conv_example_1 = [\n",
    "    {\"speaker\": \"USER\", \n",
    "    \"utterance\": \"I think science fiction is an amazing genre for anything. Future science, technology, time travel, FTL travel, they're all such interesting concepts.\",}, \n",
    "\n",
    "    # System turn should not have mentions or pems\n",
    "    {\"speaker\": \"SYSTEM\", \n",
    "    \"utterance\": \"Awesome! I really love how sci-fi storytellers focus on political/social/philosophical issues that would still be around even in the future. Makes them relatable.\",},\n",
    "\n",
    "    {\"speaker\": \"USER\", \n",
    "    \"utterance\": \"I agree. One of my favorite forms of science fiction is anything related to time travel! I find it fascinating.\",},\n",
    "]\n",
    "\n",
    "result_1 = cel.annotate(conv_example_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: I think science fiction is an amazing genre for anything. Future science, technology, time travel, FTL travel, they're all such interesting concepts.\n",
      "\t [8, 15, 'science fiction', 'Science_fiction']\n",
      "\t [38, 5, 'genre', 'Genre']\n",
      "\t [74, 10, 'technology', 'Technology']\n",
      "\t [86, 11, 'time travel', 'Time_travel']\n",
      "\t [99, 10, 'FTL travel', 'Faster-than-light']\n",
      "SYST: Awesome! I really love how sci-fi storytellers focus on political/social/philosophical issues that would still be around even in the future. Makes them relatable.\n",
      "USER: I agree. One of my favorite forms of science fiction is anything related to time travel! I find it fascinating.\n",
      "\t [37, 15, 'science fiction', 'Science_fiction']\n",
      "\t [76, 11, 'time travel', 'Time_travel']\n",
      "\t [16, 36, 'my favorite forms of science fiction', 'Time_travel']\n"
     ]
    }
   ],
   "source": [
    "print_results(result_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "conv_example_2 = [\n",
    "    {\"speaker\": \"USER\", \n",
    "    \"utterance\": \"I am allergic to tomatoes but we have a lot of famous Italian restaurants here in London.\",}, \n",
    "\n",
    "    # System turn should not have mentions or pems\n",
    "    {\"speaker\": \"SYSTEM\", \n",
    "    \"utterance\": \"Some people are allergic to histamine in tomatoes.\",},\n",
    "\n",
    "    {\"speaker\": \"USER\", \n",
    "    \"utterance\": \"Talking of food, can you recommend me a restaurant in my city for our anniversary?\",},\n",
    "]\n",
    "\n",
    "result_2 = cel.annotate(conv_example_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: I am allergic to tomatoes but we have a lot of famous Italian restaurants here in London.\n",
      "\t [17, 8, 'tomatoes', 'Tomato']\n",
      "\t [54, 19, 'Italian restaurants', 'Italian_cuisine']\n",
      "\t [82, 6, 'London', 'London']\n",
      "SYST: Some people are allergic to histamine in tomatoes.\n",
      "USER: Talking of food, can you recommend me a restaurant in my city for our anniversary?\n",
      "\t [11, 4, 'food', 'Food']\n",
      "\t [40, 10, 'restaurant', 'Restaurant']\n",
      "\t [54, 7, 'my city', 'London']\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print_results(result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a53556614ea0d196de1dd499c6cd4b1019f00d4a13a34e20ba99029df2a473df"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('220429_conel22_github')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
